L. Zhu, H. Xing, W. Sun, S. Du and D. Fan, "Semi-supervised semantic remote sensing image change detection using multimodal spatio-temporal association knowledge," in IEEE Transactions on Geoscience and Remote Sensing, doi: 10.1109/TGRS.2025.3621732. 
https://ieeexplore.ieee.org/document/11204654
 
 As shown in Fig. 1, the MST-AK method mainly consists of the pre-training weights of the ResNet-34 network, the CLIP-based descriptive cue textual knowledge module of the land cover type, the image-text channel attention and image-text spatial attention based feature extraction module, the difference change feature fusion representation module, the three-branch interactive spatio-temporal association module, image-text change difference-based loss function computation module, three-branch change difference-based loss function computation module, and change magnitude-based adaptive threshold selection method.
![1](https://github.com/user-attachments/assets/4deee026-f51a-4983-89b0-1898b1540982)
Fig. 1. Framework of the MST-AK method
